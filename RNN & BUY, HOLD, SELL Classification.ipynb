{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4363d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc2dd3c",
   "metadata": {},
   "source": [
    "For the data to be processed, we need to do some cleaning and transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72e425",
   "metadata": {},
   "source": [
    "- Convert date format\n",
    "- Change Vol. from percentage to real numbers\n",
    "- Change values from million, and K to real numbers\n",
    "- Changing data type from Object to float for some of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e68040a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/3666261852.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dateparse = lambda dates: pd.datetime.strptime(dates, '%b %d, %Y')\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/3666261852.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dateparse = lambda dates: pd.datetime.strptime(dates, '%b %d, %Y')\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/3666261852.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dateparse = lambda dates: pd.datetime.strptime(dates, '%b %d, %Y')\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/3666261852.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  dateparse = lambda dates: pd.datetime.strptime(dates, '%b %d, %Y')\n"
     ]
    }
   ],
   "source": [
    "dateparse = lambda dates: pd.datetime.strptime(dates, '%b %d, %Y')\n",
    "# loading data for Argentina\n",
    "argentina_df = pd.read_csv('data/argentina.csv',sep=',', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n",
    "argentina_df['Vol.'] = (argentina_df['Vol.'].replace(r'[KM]+$', '', regex=True)\n",
    "                           .astype(float) * argentina_df['Vol.'].str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n",
    "                           .fillna(1).replace(['K','M'], [10**3, 10**6]).astype(int))\n",
    "\n",
    "# loading data for Brazil\n",
    "brazil_df = pd.read_csv('data/brazil.csv',sep=',', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n",
    "brazil_df['Vol.'] = (brazil_df['Vol.'].replace(r'[KM]+$', '', regex=True)\n",
    "                           .astype(float) * brazil_df['Vol.'].str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n",
    "                           .fillna(1).replace(['K','M'], [10**3, 10**6]).astype(int))\n",
    "\n",
    "# loading data for Colombia\n",
    "colombia_df = pd.read_csv('data/colombia.csv',sep=',', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n",
    "colombia_df['Vol.'] = (colombia_df['Vol.'].replace(r'[KM]+$', '', regex=True)\n",
    "                           .astype(float) * colombia_df['Vol.'].str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n",
    "                           .fillna(1).replace(['K','M'], [10**3, 10**6]).astype(int))\n",
    "colombia_df['Price'] = colombia_df['Price'].str.replace(',', '')\n",
    "colombia_df['Price'] = colombia_df['Price'].astype(float)\n",
    "colombia_df['Open'] = colombia_df['Open'].str.replace(',', '')\n",
    "colombia_df['Open'] = colombia_df['Open'].astype(float)\n",
    "colombia_df['High'] = colombia_df['High'].str.replace(',', '')\n",
    "colombia_df['High'] = colombia_df['High'].astype(float)\n",
    "colombia_df['Low'] = colombia_df['Low'].str.replace(',', '')\n",
    "colombia_df['Low'] = colombia_df['Low'].astype(float)\n",
    "\n",
    "# loading data for Egypt\n",
    "egypt_df = pd.read_csv('data/egypt.csv',sep=',', parse_dates=['Date'], date_parser=dateparse).fillna(0)\n",
    "egypt_df['Vol.'] = (egypt_df['Vol.'].replace(r'[KM]+$', '', regex=True)\n",
    "                           .astype(float) * egypt_df['Vol.'].str.extract(r'[\\d\\.]+([KM]+)', expand=False)\n",
    "                           .fillna(1).replace(['K','M'], [10**3, 10**6]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca5d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize values to feed to RNN\n",
    "def normalize_data(df):\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['Open'] = min_max_scaler.fit_transform(df.Open.values.reshape(-1,1))\n",
    "    df['High'] = min_max_scaler.fit_transform(df.High.values.reshape(-1,1))\n",
    "    df['Low'] = min_max_scaler.fit_transform(df.Low.values.reshape(-1,1))\n",
    "    df['Price'] = min_max_scaler.fit_transform(df.Price.values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "724712fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for splitting data into train, test, and validation\n",
    "def split_data(df):\n",
    "    start_date = '2021-01-01' \n",
    "    end_date = '2021-03-31'\n",
    "    val_start_date = '2020-12-01' \n",
    "    val_end_date = '2020-12-30'\n",
    "    test = df.loc[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    remaining = df[~df.index.isin(test.index)]\n",
    "    val_data = remaining.loc[(remaining['Date'] >= val_start_date) & (remaining['Date'] <= val_end_date)]\n",
    "    train = remaining[~remaining.index.isin(val_data.index)]\n",
    "    # Making Date as the index for time series problem. \n",
    "    x_train = train[['Date','Price','Open','High','Low']]\n",
    "    x_train['Date'] = pd.to_datetime(train['Date'])\n",
    "    x_train.set_index('Date', inplace=True)\n",
    "    val_train = val_data[['Date','Price','Open','High','Low']]\n",
    "    val_train['Date'] = pd.to_datetime(val_data['Date'])\n",
    "    val_train.set_index('Date', inplace=True)\n",
    "    y_test = test[['Date','Price','Open','High','Low']]\n",
    "    y_test['Date'] = pd.to_datetime(y_test['Date'])\n",
    "    y_test.set_index('Date', inplace=True)\n",
    "    # For training, we're only interested in the Open, High, and Low columns. \n",
    "    X_train = np.array(x_train[['Open','High','Low']])\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    Y_train = x_train['Price']\n",
    "    X_val = np.array(val_train[['Open','High','Low']])\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "    Y_val = val_train['Price']\n",
    "    X_test = np.array(y_test[['Open','High','Low']])\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    Y_test = y_test['Price']\n",
    "    return X_train,Y_train,X_val,Y_val,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5744c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.GRU(64, input_shape=(3, 1), return_sequences=True))\n",
    "model.add(layers.LSTM(64, return_sequences=True))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.LSTM(32, return_sequences=False))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82fce48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and evaluate function\n",
    "def train_eval(model,X_train, Y_train, X_val, Y_val, X_test, Y_test, period,stock_name):\n",
    "    history = model.fit(X_train, Y_train, epochs=50, batch_size=16, validation_data=(X_val, Y_val))\n",
    "    # Evaluate the model on the test set\n",
    "    mae = model.evaluate(X_test[:period], Y_test[:period])\n",
    "    print('MAE for '+stock_name+' for',period,' days', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7ba8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0346\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0333\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0233\n",
      "Epoch 4/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['Date'] = pd.to_datetime(train['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_train['Date'] = pd.to_datetime(val_data['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['Date'] = pd.to_datetime(y_test['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0245\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0272\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0274\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0276\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0323\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0256\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0393\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0266\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0284\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0322\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0234\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0258\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0398\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0402\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0288\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0264\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0363\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0265\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0340\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.0285\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0360\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0278\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0246\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0250\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0254\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0231\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0281\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0266\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0627\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0267\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0223\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0225\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0254\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0287\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0351\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0217\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0553\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0222\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0287\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0342\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0240\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0276\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0233\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0275\n",
      "MAE for Argentina for 7  days 0.02747230790555477\n"
     ]
    }
   ],
   "source": [
    "# For Argentina\n",
    "normalized_data = normalize_data(argentina_df)\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = split_data(normalized_data)\n",
    "# Train the model\n",
    "train_eval(model,X_train,Y_train,X_val,Y_val,X_test,Y_test,7,\"Argentina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dadb9ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0135\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0132\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0143\n",
      "Epoch 4/50\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.0289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['Date'] = pd.to_datetime(train['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_train['Date'] = pd.to_datetime(val_data['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['Date'] = pd.to_datetime(y_test['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0121\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0124\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0159\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0145\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0199\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0156\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0153\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0136\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0129\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0122\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0227\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0160\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0179\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0221\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0121\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0126\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0195\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0166\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0141\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0135\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0123\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0130\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0172\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0124\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0122\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0147\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0135\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0146\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0170\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0150\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0131\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0122\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0119\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0122\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0139\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0161\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0158\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0119\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0129\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0135\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0130\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0140\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0198\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0145\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0139\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0165\n",
      "MAE for Brazil for 7  days 0.016528228297829628\n"
     ]
    }
   ],
   "source": [
    "# For Brazil\n",
    "normalized_data = normalize_data(brazil_df)\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = split_data(normalized_data)\n",
    "# Train the model\n",
    "train_eval(model,X_train,Y_train,X_val,Y_val,X_test,Y_test,7,\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e9aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0342\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0143\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0168\n",
      "Epoch 4/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['Date'] = pd.to_datetime(train['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_train['Date'] = pd.to_datetime(val_data['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['Date'] = pd.to_datetime(y_test['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0166\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0167\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0170\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0176\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0146\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0156\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0180\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0256\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0146\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0180\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0226\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0150\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0151\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0157\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0144\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0149\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0175\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0150\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0147\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0150\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0155\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0147\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0214\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0140\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0139\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0139\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0161\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0145\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0158\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0197\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0158\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0140\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0182\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0236\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0141\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0177\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0136\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0135\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0180\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0139\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0134\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "MAE for Colombia for 7  days 0.004963976796716452\n"
     ]
    }
   ],
   "source": [
    "# For Colombia\n",
    "normalized_data = normalize_data(colombia_df)\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = split_data(normalized_data)\n",
    "# Train the model\n",
    "train_eval(model,X_train,Y_train,X_val,Y_val,X_test,Y_test,7,\"Colombia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c27bb829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0061\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      " 1/14 [=>............................] - ETA: 0s - loss: 0.0114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_train['Date'] = pd.to_datetime(train['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_train['Date'] = pd.to_datetime(val_data['Date'])\n",
      "/var/folders/tc/qfc76dxj7456z8tqv6mk4xfh0000gn/T/ipykernel_33093/1071198107.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test['Date'] = pd.to_datetime(y_test['Date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0117\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0062\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0197\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0202\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0064\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0106\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0060\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0063\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0083\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0064\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0077\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0059\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0059\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0098\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0060\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0057\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0073\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0117\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0067\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0055\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0058\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0083\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0063\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0066\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0075\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0075\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0087\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0146\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0071\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0117\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0077\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0062\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0075\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0087\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0081\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0073\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "MAE for Egypt for 7  days 0.007944741286337376\n"
     ]
    }
   ],
   "source": [
    "# For Egypt\n",
    "normalized_data = normalize_data(egypt_df)\n",
    "X_train,Y_train,X_val,Y_val,X_test,Y_test = split_data(normalized_data)\n",
    "# Train the model\n",
    "train_eval(model,X_train,Y_train,X_val,Y_val,X_test,Y_test,7,\"Egypt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee79b4",
   "metadata": {},
   "source": [
    "# Classifying BUY HOLD, SELL signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "606b422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some essential libraries\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da6c56d",
   "metadata": {},
   "source": [
    "The first thing we need to do is to add an additional column 'Signal' that will contains three classes:\n",
    "- 0 = HOLD\n",
    "- 1 = SELL\n",
    "- 2 = BUY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "704c4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_func = lambda x: 0 if float(x.strip('%')) <= 0.10 and float(x.strip('%')) > 0.0 else 1 if float(x.strip('%')) > 0.10 else 2\n",
    "\n",
    "# Apply the lambda function to create the 'Signal' column\n",
    "argentina_df['Signal'] = argentina_df['Change %'].apply(signal_func)\n",
    "brazil_df['Signal'] = brazil_df['Change %'].apply(signal_func)\n",
    "colombia_df['Signal'] = colombia_df['Change %'].apply(signal_func)\n",
    "egypt_df['Signal'] = egypt_df['Change %'].apply(signal_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "568c1a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Change %</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>0.528926</td>\n",
       "      <td>0.534694</td>\n",
       "      <td>0.543568</td>\n",
       "      <td>0.539095</td>\n",
       "      <td>1570000.0</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>0.520661</td>\n",
       "      <td>0.522449</td>\n",
       "      <td>0.518672</td>\n",
       "      <td>0.522634</td>\n",
       "      <td>3430000.0</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>0.508264</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.506224</td>\n",
       "      <td>0.526749</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>-0.27%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.518672</td>\n",
       "      <td>0.526749</td>\n",
       "      <td>2340000.0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-25</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.526971</td>\n",
       "      <td>0.489712</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>1.37%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0.888430</td>\n",
       "      <td>0.865306</td>\n",
       "      <td>0.908714</td>\n",
       "      <td>0.884774</td>\n",
       "      <td>2090000.0</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>0.720165</td>\n",
       "      <td>3520000.0</td>\n",
       "      <td>3.04%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0.747934</td>\n",
       "      <td>0.706122</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.707819</td>\n",
       "      <td>2520000.0</td>\n",
       "      <td>-2.95%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.926531</td>\n",
       "      <td>0.908714</td>\n",
       "      <td>0.794239</td>\n",
       "      <td>3760000.0</td>\n",
       "      <td>-8.32%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.979253</td>\n",
       "      <td>0.979424</td>\n",
       "      <td>241600.0</td>\n",
       "      <td>-0.21%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date     Price      Open      High       Low       Vol. Change %  \\\n",
       "0   2021-03-31  0.528926  0.534694  0.543568  0.539095  1570000.0    0.54%   \n",
       "1   2021-03-30  0.520661  0.522449  0.518672  0.522634  3430000.0    0.81%   \n",
       "2   2021-03-29  0.508264  0.514286  0.506224  0.526749  1250000.0   -0.27%   \n",
       "3   2021-03-28  0.512397  0.542857  0.518672  0.526749  2340000.0    0.00%   \n",
       "4   2021-03-25  0.512397  0.485714  0.526971  0.489712  2500000.0    1.37%   \n",
       "..         ...       ...       ...       ...       ...        ...      ...   \n",
       "300 2020-01-09  0.888430  0.865306  0.908714  0.884774  2090000.0    4.76%   \n",
       "301 2020-01-08  0.801653  0.718367  0.863071  0.720165  3520000.0    3.04%   \n",
       "302 2020-01-06  0.747934  0.706122  0.800830  0.707819  2520000.0   -2.95%   \n",
       "303 2020-01-05  0.801653  0.926531  0.908714  0.794239  3760000.0   -8.32%   \n",
       "304 2020-01-02  0.966942  0.971429  0.979253  0.979424   241600.0   -0.21%   \n",
       "\n",
       "     Signal  \n",
       "0         1  \n",
       "1         1  \n",
       "2         2  \n",
       "3         2  \n",
       "4         1  \n",
       "..      ...  \n",
       "300       1  \n",
       "301       1  \n",
       "302       2  \n",
       "303       2  \n",
       "304       2  \n",
       "\n",
       "[305 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egypt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98ffb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new train and split function for classification\n",
    "def split_train_test(df):\n",
    "    start_date = '2021-01-01' \n",
    "    end_date = '2021-03-31'\n",
    "    test = df.loc[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "    train = df[~df.index.isin(test.index)]\n",
    "    X_train = train[['Price','Open','High','Low']]\n",
    "    y_train = train['Signal']\n",
    "    X_test = test[['Price','Open','High','Low']]\n",
    "    y_test = test['Signal']\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3baafaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for random forest\n",
    "def random_forest(X_train,y_train,X_test,y_test,stock_name):\n",
    "    # Create a Random Forest classifier with 100 trees\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the classifier on the training data\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the class labels for the test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Compute the accuracy score of the classifier\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Random Forest:: For \"+stock_name+\" stock\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c016720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for XGBoost\n",
    "def xg_boost(X_train,y_train,X_test,y_test,stock_name):\n",
    "    params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'seed': 42\n",
    "    }\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    num_rounds = 100\n",
    "    model = xgb.train(params, dtrain, num_rounds)\n",
    "    y_pred = model.predict(dtest)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"XGBoost:: For \"+stock_name+\" stock\")\n",
    "    print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
    "    print('f1 score is ', f1)\n",
    "    print('recall is ', recall)\n",
    "    print('precision score is ', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79d70250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:: For Argentina stock\n",
      "Accuracy: 0.65\n",
      "XGBoost:: For Argentina stock\n",
      "Accuracy: 63.33%\n",
      "f1 score is  0.6341490545050057\n",
      "recall is  0.6333333333333333\n",
      "precision score is  0.6406006674082314\n"
     ]
    }
   ],
   "source": [
    "normalized_data = normalize_data(argentina_df)\n",
    "X_train,y_train,X_test,y_test = split_train_test(normalized_data)\n",
    "random_forest(X_train,y_train,X_test,y_test,\"Argentina\")\n",
    "xg_boost(X_train,y_train,X_test,y_test,\"Argentina\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f97bb483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:: For Brazil stock\n",
      "Accuracy: 0.58\n",
      "XGBoost:: For Brazil stock\n",
      "Accuracy: 53.33%\n",
      "f1 score is  0.5191919191919193\n",
      "recall is  0.5333333333333333\n",
      "precision score is  0.6142857142857143\n"
     ]
    }
   ],
   "source": [
    "normalized_data = normalize_data(brazil_df)\n",
    "X_train,y_train,X_test,y_test = split_train_test(normalized_data)\n",
    "random_forest(X_train,y_train,X_test,y_test,\"Brazil\")\n",
    "xg_boost(X_train,y_train,X_test,y_test,\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0fb16b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:: For Colombia stock\n",
      "Accuracy: 0.57\n",
      "XGBoost:: For Colombia stock\n",
      "Accuracy: 59.02%\n",
      "f1 score is  0.5803278688524589\n",
      "recall is  0.5901639344262295\n",
      "precision score is  0.5966492523869573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tf/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "normalized_data = normalize_data(colombia_df)\n",
    "X_train,y_train,X_test,y_test = split_train_test(normalized_data)\n",
    "random_forest(X_train,y_train,X_test,y_test,\"Colombia\")\n",
    "xg_boost(X_train,y_train,X_test,y_test,\"Colombia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7360f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:: For Egypt stock\n",
      "Accuracy: 0.48\n",
      "XGBoost:: For Egypt stock\n",
      "Accuracy: 54.84%\n",
      "f1 score is  0.5483870967741935\n",
      "recall is  0.5483870967741935\n",
      "precision score is  0.5483870967741935\n"
     ]
    }
   ],
   "source": [
    "normalized_data = normalize_data(egypt_df)\n",
    "X_train,y_train,X_test,y_test = split_train_test(normalized_data)\n",
    "random_forest(X_train,y_train,X_test,y_test,\"Egypt\")\n",
    "xg_boost(X_train,y_train,X_test,y_test,\"Egypt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
